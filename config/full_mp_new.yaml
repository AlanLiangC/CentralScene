hyper:
    batch_size: 64
    gpu_ids: 0
    logs_dir: ../full_mp/diff_crossattn
    results_dir: ../full_mp/diff_crossattn
    name: ./
    isTrain: True
    device: 'cuda'
    distributed: 0
    lr_init: 1e-4
    lr_step: [35000, 70000, 140000]
    lr_evo: [5e-5, 1e-5, 5e-6]
dataset:
    res: 64
    trunc_thres: 0.2
    ratio: 1
    lidar_scene:
      box_range: &box_range [-50, -50,-4, 50, 50, 2]
      # raw_path: /home/alan/AlanLiang/Dataset/Nuscenes/v1.0-trainval
      raw_path: /mnt/scratch/e/e1493786/AlanLiang/Dataset/Nuscenes/v1.0-trainval
      size: &size [32, 1024]
      fov: &fov [ 10,-30 ]
      depth_range: [ 1.0,56.0 ]
      depth_scale: 5.84  # np.log2(depth_max + 1)
      log_scale: true
      x_range: [ -50.0, 50.0 ]
      y_range: [ -50.0, 50.0 ]
      z_range: [ -4.0, 2.0 ]

layout_branch:
    model: diffusion_scene_layout_ddpm
    angle_dim: 2
    denoiser: unet1d
    relation_condition: true
    denoiser_kwargs:
        dims: 1 # 1D
        in_channels: 8 # size(3)+loc(3)+sincos(2)
        out_channels: 8 # same
        model_channels: 512
        channel_mult: [ 1,1,1,1]
        num_res_blocks: 2
        attention_resolutions: [ 4, 2 ]
        num_heads: 8
        # cond_model params
        use_spatial_transformer: true
        transformer_depth: 1
        conditioning_key: 'crossattn'
        concat_dim: 1280
        crossattn_dim: 1280
        use_checkpoint: true
        enable_t_emb: true

    diffusion_kwargs:
      schedule_type: 'linear'
      beta_start: 0.0001
      beta_end: 0.02
      time_num: 1000
      model_mean_type: 'eps'
      model_var_type: 'fixedsmall'
      loss_separate: true
      loss_iou: false
      iou_type: obb
      train_stats_file: null


shape_branch:
    linear_start: 0.0015
    linear_end: 0.0195
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    image_size: [8, 128]
    channels: 8
    monitor: val/loss_simple_ema
    first_stage_key: image
    cond_stage_key: layout
    conditioning_key: crossattn
    cond_stage_trainable: true
    verbose: false
    unet_config:
      target: lidm.modules.diffusion.openaimodel.UNetModel
      params:
        image_size: [8, 128]
        in_channels: 8
        out_channels: 8
        model_channels: 256
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4]
        num_head_channels: 32
        lib_name: lidm
    first_stage_config:
      target: lidm.models.autoencoder.VQModelInterface
      params:
        embed_dim: 8
        n_embed: 16384
        lib_name: lidm
        use_mask: False  # False
        ckpt_path: ../model/first_stage_models/nusc/f_c2_p4/last.ckpt
        ddconfig:
          double_z: false
          z_channels: 8
          in_channels: 1
          out_ch: 1
          ch: 64
          ch_mult: [1,2,2,4]
          strides: [[1,2],[2,2],[2,2]]
          num_res_blocks: 2
          attn_levels: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity
    cond_convert_config:
      box_range: *box_range
      size: *size
      fov: *fov
      out_channels: 32
      project_ds_scale: 4
      up_factor: 4

    cond_stage_config:
      target: lidm.modules.encoders.modules.SpatialRescaler
      params:
        strides: [[1,2],[2,2],[2,2]]
        in_channels: 32
        out_channels: 8    
misc:
    debug: 0
    seed: 111
    backend: gloo
    local_rank: 0

training:
    lr: 1e-5
    lr_policy: lambda
    lr_decay_iters: 50
    lambda_L1: 10.0
